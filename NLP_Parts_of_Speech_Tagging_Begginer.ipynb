{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Parts-of-Speech-Tagging-Begginer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPw9n5apx0didKxODqzfAu+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-alamdari/NLP-Parts-of-Speech-Tagging-Begginer/blob/main/NLP_Parts_of_Speech_Tagging_Begginer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "TrZXsr_1HMnT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Probabilistic%20Models/Week%202/WSJ_24.pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYFdEwFvHYZj",
        "outputId": "7315eea7-4c53-414b-fc0b-fcdccaadfae6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-15 12:00:45--  https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Probabilistic%20Models/Week%202/WSJ_24.pos\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 286063 (279K) [text/plain]\n",
            "Saving to: ‘WSJ_24.pos.1’\n",
            "\n",
            "\rWSJ_24.pos.1          0%[                    ]       0  --.-KB/s               \rWSJ_24.pos.1        100%[===================>] 279.36K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-04-15 12:00:45 (12.4 MB/s) - ‘WSJ_24.pos.1’ saved [286063/286063]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Probabilistic%20Models/Week%202/WSJ_02-21.pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8FVO2vXIJcx",
        "outputId": "fbd857c1-ab79-4bab-eecd-2465d13f2ed9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-15 12:00:46--  https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Probabilistic%20Models/Week%202/WSJ_02-21.pos\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8279089 (7.9M) [text/plain]\n",
            "Saving to: ‘WSJ_02-21.pos.1’\n",
            "\n",
            "\rWSJ_02-21.pos.1       0%[                    ]       0  --.-KB/s               \rWSJ_02-21.pos.1     100%[===================>]   7.90M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-04-15 12:00:46 (115 MB/s) - ‘WSJ_02-21.pos.1’ saved [8279089/8279089]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Probabilistic%20Models/Week%202/hmm_vocab.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY1AzKe5Iati",
        "outputId": "3add38f3-f6b6-4333-aa48-caec804bfff9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-15 12:03:04--  https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Probabilistic%20Models/Week%202/hmm_vocab.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 196571 (192K) [text/plain]\n",
            "Saving to: ‘hmm_vocab.txt’\n",
            "\n",
            "hmm_vocab.txt       100%[===================>] 191.96K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-04-15 12:03:04 (10.4 MB/s) - ‘hmm_vocab.txt’ saved [196571/196571]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('WSJ_02-21.pos', 'r') as f:\n",
        "  train_corpus = f.readlines()"
      ],
      "metadata": {
        "id": "CavVoovII8XA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus[10: 20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS2weJQDKE_c",
        "outputId": "5a532853-ae0e-4f55-94e6-877773e89abf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['at\\tIN\\n',\n",
              " 'Chicago\\tNNP\\n',\n",
              " \"'s\\tPOS\\n\",\n",
              " 'Goodman\\tNNP\\n',\n",
              " 'Theatre\\tNNP\\n',\n",
              " '(\\t(\\n',\n",
              " '``\\t``\\n',\n",
              " 'Revitalized\\tVBN\\n',\n",
              " 'Classics\\tNNS\\n',\n",
              " 'Take\\tVBP\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('WSJ_24.pos', 'r') as f:\n",
        "  y = f.readlines()"
      ],
      "metadata": {
        "id": "a_zJ20e5KHo9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[10: 20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaUTRDeDKVAX",
        "outputId": "c284347b-fa68-4094-d331-b40f9aff5ab6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['points\\tNNS\\n',\n",
              " 'this\\tDT\\n',\n",
              " 'week\\tNN\\n',\n",
              " ',\\t,\\n',\n",
              " 'with\\tIN\\n',\n",
              " 'readings\\tNNS\\n',\n",
              " 'on\\tIN\\n',\n",
              " 'trade\\tNN\\n',\n",
              " ',\\t,\\n',\n",
              " 'output\\tNN\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('hmm_vocab.txt', 'r') as f:\n",
        "  vocabulary_list = f.read().split('\\n')\n",
        "\n",
        "vocab = {}\n",
        "for ind, word in enumerate(sorted(vocabulary_list)):\n",
        "  vocab[word] = ind"
      ],
      "metadata": {
        "id": "2o-Bvo-NKWL2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(vocabulary_list)[10: 20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDmdlb89I7r8",
        "outputId": "d91c1e59-1541-4790-ecbd-7edaebb5cd92"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"'70s\", \"'80s\", \"'86\", \"'90s\", \"'N\", \"'S\", \"'d\", \"'em\", \"'ll\", \"'m\"]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for id, (k, v) in enumerate(vocab.items()):\n",
        "  print(k, v)\n",
        "  if id == 10:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCAwzGojI74W",
        "outputId": "75e057f8-dfa9-432e-b130-81d3b929aa62"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0\n",
            "! 1\n",
            "# 2\n",
            "$ 3\n",
            "% 4\n",
            "& 5\n",
            "' 6\n",
            "'' 7\n",
            "'40s 8\n",
            "'60s 9\n",
            "'70s 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/amanjeetsahu/Natural-Language-Processing-Specialization/blob/master/Natural%20Language%20Processing%20with%20Probabilistic%20Models/Week%202/utils_pos.py\n",
        "\n",
        "import string\n",
        "\n",
        "\n",
        "# Punctuation characters\n",
        "punct = set(string.punctuation)\n",
        "\n",
        "# Morphology rules used to assign unknown word tokens\n",
        "noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
        "verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
        "adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
        "adv_suffix = [\"ward\", \"wards\", \"wise\"]\n",
        "\n",
        "\n",
        "\n",
        "def word_tag_spliter(word_tag, vocab):\n",
        "\n",
        "  if word_tag.split():\n",
        "    word, tag = word_tag.split()\n",
        "    if not vocab.get(word):\n",
        "      word = assign_unk(word)\n",
        "  else:\n",
        "      word, tag = '--n--', '--s--'\n",
        "  \n",
        "  return word, tag\n",
        "\n",
        "def assign_unk(tok):\n",
        "    \"\"\"\n",
        "    Assign unknown word tokens\n",
        "    \"\"\"\n",
        "    # Digits\n",
        "    if any(char.isdigit() for char in tok):\n",
        "        return \"--unk_digit--\"\n",
        "\n",
        "    # Punctuation\n",
        "    elif any(char in punct for char in tok):\n",
        "        return \"--unk_punct--\"\n",
        "\n",
        "    # Upper-case\n",
        "    elif any(char.isupper() for char in tok):\n",
        "        return \"--unk_upper--\"\n",
        "\n",
        "    # Nouns\n",
        "    elif any(tok.endswith(suffix) for suffix in noun_suffix):\n",
        "        return \"--unk_noun--\"\n",
        "\n",
        "    # Verbs\n",
        "    elif any(tok.endswith(suffix) for suffix in verb_suffix):\n",
        "        return \"--unk_verb--\"\n",
        "\n",
        "    # Adjectives\n",
        "    elif any(tok.endswith(suffix) for suffix in adj_suffix):\n",
        "        return \"--unk_adj--\"\n",
        "\n",
        "    # Adverbs\n",
        "    elif any(tok.endswith(suffix) for suffix in adv_suffix):\n",
        "        return \"--unk_adv--\"\n",
        "\n",
        "    return \"--unk--\"\n",
        "\n",
        "def preprocess(vocab, data_fp):\n",
        "    \"\"\"\n",
        "    Preprocess data\n",
        "    \"\"\"\n",
        "    orig = []\n",
        "    prep = []\n",
        "\n",
        "    with open(data_fp, \"r\") as data_file:\n",
        "        for cnt, word in enumerate(data_file):\n",
        "            # End of sentence\n",
        "            if not word.split():\n",
        "                orig.append(word.strip())\n",
        "                word = \"--n--\"\n",
        "                prep.append(word)\n",
        "                continue\n",
        "\n",
        "            # Handle unknown words\n",
        "            elif word.strip() not in vocab:\n",
        "                orig.append(word.strip())\n",
        "                word = assign_unk(word)\n",
        "                prep.append(word)\n",
        "                continue\n",
        "\n",
        "            else:\n",
        "                orig.append(word.strip())\n",
        "                prep.append(word.strip())\n",
        "\n",
        "    assert(len(orig) == len(open(data_fp, \"r\").readlines()))\n",
        "    assert(len(prep) == len(open(data_fp, \"r\").readlines()))\n",
        "\n",
        "    return orig, prep\n"
      ],
      "metadata": {
        "id": "a1GOoR6hJJ34"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Probabilistic%20Models/Week%202/test.words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcQocgb7P1mT",
        "outputId": "e0908cd0-d134-45e1-cb0a-d17f839fcf63"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-15 12:43:47--  https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Probabilistic%20Models/Week%202/test.words\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180266 (176K) [text/plain]\n",
            "Saving to: ‘test.words’\n",
            "\n",
            "test.words          100%[===================>] 176.04K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-04-15 12:43:47 (11.6 MB/s) - ‘test.words’ saved [180266/180266]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, prep = preprocess(vocab, 'test.words')"
      ],
      "metadata": {
        "id": "UyTgNoipQD8n"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prep[10:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUnZI7VSQKu0",
        "outputId": "9ecbc46a-0807-480e-f88b-d0b07077c04f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['points',\n",
              " 'this',\n",
              " 'week',\n",
              " ',',\n",
              " 'with',\n",
              " 'readings',\n",
              " 'on',\n",
              " 'trade',\n",
              " ',',\n",
              " 'output']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def dictionary_creator(corpus, vocab):\n",
        "  emission_counts = defaultdict(int)\n",
        "  transition_counts = defaultdict(int)\n",
        "  tag_counts = defaultdict(int)\n",
        "  prev_tag = '--s--'\n",
        "  for word_tag in corpus:\n",
        "    word, tag = word_tag_spliter(word_tag, vocab)\n",
        "\n",
        "    transition_counts[(prev_tag, tag)] += 1\n",
        "    emission_counts[(tag, word)] += 1\n",
        "    tag_counts[tag] += 1\n",
        "    prev_tag = tag\n",
        "  \n",
        "  return emission_counts, transition_counts, tag_counts "
      ],
      "metadata": {
        "id": "O9cSGiTNQNNU"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emission_counts, transition_counts, tag_counts = dictionary_creator(train_corpus, vocab)"
      ],
      "metadata": {
        "id": "mrYVIrFjQsBv"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(emission_counts.items()):\n",
        "  print(item[0], item[1])\n",
        "  if i == 20:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-t9IdK9RZy_",
        "outputId": "ce0be4f2-25df-4478-a118-80cb52ddf755"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('IN', 'In') 1735\n",
            "('DT', 'an') 3142\n",
            "('NNP', 'Oct.') 317\n",
            "('CD', '19') 100\n",
            "('NN', 'review') 36\n",
            "('IN', 'of') 22925\n",
            "('``', '``') 6967\n",
            "('DT', 'The') 6795\n",
            "('NN', 'Misanthrope') 3\n",
            "(\"''\", \"''\") 6787\n",
            "('IN', 'at') 4361\n",
            "('NNP', 'Chicago') 197\n",
            "('POS', \"'s\") 8079\n",
            "('NNP', 'Goodman') 7\n",
            "('NNP', 'Theatre') 5\n",
            "('(', '(') 1153\n",
            "('VBN', '--unk_upper--') 93\n",
            "('NNS', '--unk_upper--') 350\n",
            "('VBP', 'Take') 1\n",
            "('DT', 'the') 41098\n",
            "('NN', 'Stage') 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(transition_counts.items()):\n",
        "  print(item[0], item[1])\n",
        "  if i == 20:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26AgaW-1ZK8Q",
        "outputId": "472517a2-3b20-4f7e-e84e-8c5a99758192"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('--s--', 'IN') 5050\n",
            "('IN', 'DT') 32364\n",
            "('DT', 'NNP') 9044\n",
            "('NNP', 'CD') 1752\n",
            "('CD', 'NN') 7377\n",
            "('NN', 'IN') 32885\n",
            "('IN', '``') 546\n",
            "('``', 'DT') 1014\n",
            "('DT', 'NN') 38873\n",
            "('NN', \"''\") 686\n",
            "(\"''\", 'IN') 591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(tag_counts.items()):\n",
        "  print(item[0], item[1])\n",
        "  if i == 20:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL0sTLqmZOc-",
        "outputId": "d2afdf6c-fb26-4b5b-8ff8-84945a34e352"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IN 98554\n",
            "DT 81842\n",
            "NNP 91466\n",
            "CD 36568\n",
            "NN 132935\n",
            "`` 7092\n",
            "'' 6919\n",
            "POS 8701\n",
            "( 1366\n",
            "VBN 20024\n",
            "NNS 59856\n",
            "VBP 12491\n",
            ", 48727\n",
            "CC 23947\n",
            ") 1376\n",
            "VBD 29889\n",
            "RB 30970\n",
            "TO 22357\n",
            ". 39478\n",
            "--s-- 39832\n",
            "VBZ 21672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pos_predictor(prep, y, emission_counts, vocab, states): \n",
        "  corrects = 0\n",
        "  total = len(y)\n",
        "  words = set(emission_counts.keys())\n",
        "\n",
        "  for word, word_pos in zip(prep, y):\n",
        "    \n",
        "    if len(word_pos) == 1:\n",
        "      continue\n",
        "\n",
        "    true_word, true_pos = word_pos.split()\n",
        "    final_count, final_pos = 0, ''\n",
        " \n",
        "    if vocab.get(word):\n",
        "      for pos in states:\n",
        "        \n",
        "        key = (pos, word)\n",
        "        count = emission_counts.get(key)\n",
        "        \n",
        "        if count != None and count > final_count:\n",
        "          final_count = count\n",
        "          final_pos = pos\n",
        "      \n",
        "      if final_pos == true_pos:\n",
        "        corrects += 1\n",
        "\n",
        "  accuracy = corrects / total\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "Dvheg5pNZPeg"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_predictor(prep, y, emission_counts, vocab, states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io8Mnu77gbrl",
        "outputId": "827a693a-3699-4900-b2f9-6bfbf3012273"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8888563993099213"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqJBPD-Vg6zG",
        "outputId": "8b8acb16-b858-407b-efb7-f27b83b8076f"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['#',\n",
              " '$',\n",
              " \"''\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '--s--',\n",
              " '.',\n",
              " ':',\n",
              " 'CC',\n",
              " 'CD',\n",
              " 'DT',\n",
              " 'EX',\n",
              " 'FW',\n",
              " 'IN',\n",
              " 'JJ',\n",
              " 'JJR',\n",
              " 'JJS',\n",
              " 'LS',\n",
              " 'MD',\n",
              " 'NN',\n",
              " 'NNP',\n",
              " 'NNPS',\n",
              " 'NNS',\n",
              " 'PDT',\n",
              " 'POS',\n",
              " 'PRP',\n",
              " 'PRP$',\n",
              " 'RB',\n",
              " 'RBR',\n",
              " 'RBS',\n",
              " 'RP',\n",
              " 'SYM',\n",
              " 'TO',\n",
              " 'UH',\n",
              " 'VB',\n",
              " 'VBD',\n",
              " 'VBG',\n",
              " 'VBN',\n",
              " 'VBP',\n",
              " 'VBZ',\n",
              " 'WDT',\n",
              " 'WP',\n",
              " 'WP$',\n",
              " 'WRB',\n",
              " '``']"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IqbnvGyVhOc2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}